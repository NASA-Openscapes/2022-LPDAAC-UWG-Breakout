[
  {
    "objectID": "cloud-paradigm.html",
    "href": "cloud-paradigm.html",
    "title": "NASA and the Cloud Paradigm",
    "section": "",
    "text": "Slides that introduce NASA Earthdata Cloud & the Cloud Paradigm."
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "2022 ECOSTRESS Cloud Workshop",
    "section": "Welcome",
    "text": "Welcome\n\nWelcome to the 2022 ECOSTRESS Cloud Workshop hosted by NASA’s Land Processes Distributed Activate Archive (LP DAAC) with support from NASA Openscapes.\nThe workshop will take place virtually daily on April 12 and 13, 2022 from 2pm-5:30pm PST (UTC-7)."
  },
  {
    "objectID": "index.html#about",
    "href": "index.html#about",
    "title": "2022 ECOSTRESS Cloud Workshop",
    "section": "About",
    "text": "About\n\nWorkshop Goal\nThe goal of the workshop is expose ECOSTRESS data users to ECOSTRESS version 2 (v2) data products in the cloud. Learning objectives focus on how to find and access ECOSTRESS v2 data from Earthdata Cloud either by downloading or accessing the data on the cloud. The LP DAAC is the NASA archive for ECOSTRESS data products. ECOSTRESS v2 data products will hosted in the NASA Earthdata Cloud, hosted in AWS.\n\n\nWorkshop Description\nThe goal of the workshop is expose ECOSTRESS data users to ECOSTRESS version 2 data products in the cloud. Learning objectives focus on how to finda and access ECOSTRESS version 2 data from Earthdata Cloud either by downloading or accessing the data on the cloud. The LP DAAC is the NASA archive for ECOSTRESS data products. ECOSTRESS version 2 data products will hosted in the NASA Earthdata Cloud, hosted in AWS.\nThe workshop will demonstrate how to find, access, and download ECOSTRESS v2 data from the Earthdata Cloud. Participants will learn how to search for and download data from NASA’s Earthdata Search Client, a graphical user interface (GUI) for search, discovery, and download application for also EOSDIS data assets. Participants will also learn how to perform in-could data search, access, and processing routines where no data download is required, and data analysis can take place next to the data in the cloud.\n\n\nWorkshop Outcomes\nAt the end of the two days, participants should be able to find and access ECOSTRESS v2 data in the NASA Earthdata Cloud (hosted in AWS). Workshop materials will be available for future reference following the completion of the workshop/ECOSTRESS Science Team meeting\n\nNOTE: ECOSTRESS v2 data will only be available to approved individuals. Please work with Christine Lee (christine.m.lee@jpl.nasa.gov) to have your name added to the allowlist."
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "2022 ECOSTRESS Cloud Workshop",
    "section": "Acknowledgements",
    "text": "Acknowledgements\n2022 ECOSTRESS Cloud Workshop is hosted by NASA’s LP DAAC with support from the NASA Openscapes Project, with cloud computing infrastructure by 2i2c."
  },
  {
    "objectID": "further-resources.html#a-growing-list-of-resources",
    "href": "further-resources.html#a-growing-list-of-resources",
    "title": "Additional resources",
    "section": "A growing list of resources!",
    "text": "A growing list of resources!\n\nOne stop for PO.DAAC Cloud Information: Cloud Data page with About, Cloud Datasets, Access Data, FAQs, Resources, and Migration information\nAsk questions or find resources: PO.DAAC in the CLOUD Forum\nCloud user migration overview, guidance, and resources: PO.DAAC Webinar\nSearch and get access links: Earthdata Search Client and guide\nSearch and get access links: PO.DAAC Cloud Earthdata Search Portal\nBrowse cloud data in web-based browser: CMR Virtual Browse and guiding video\nScripted data search end-point: Earthdata Common Metadata Repository (CMR) API\nEnable data download or access: Obtain Earthdata Login Account\nDownload data regularly: PO.DAAC Data Subscriber Access video and PO.DAAC Data Subscriber instructions\nBulk Download guide\nOPeNDAP in the cloud\nPO.DAAC scripts and notebooks: PO.DAAC Github\nHow to get started in the AWS cloud: Earthdata Cloud Primer documents\n2021 NASA Cloud Hackathon - November 2021, co-hosted by PODAAC, NSIDC DAAC, and LPDAAC. Additional support is provided by ASDC, GESDISC, IMPACT, and Openscapes.\nNASA Earthdata: How to Cloud\nSetting up Jupyter Notebooks in a user EC2 instance in AWS - helpful blog post for setting up jupyter notebooks in an EC2 instance in AWS. (Builds on the Cloud Primer tutorials, which are missing that next step)"
  },
  {
    "objectID": "further-resources.html#additional-tutorials",
    "href": "further-resources.html#additional-tutorials",
    "title": "Additional resources",
    "section": "Additional tutorials",
    "text": "Additional tutorials\n\nData_Access__Direct_S3_Access__PODAAC_ECCO_SSH using CMR-STAC API to retrieve S3 links\nDirect access to ECCO data in S3 (from us-west-2) - Direct S3 access example with netCDF data\nDirect_S3_Access__gdalvrt\nDirect_S3_Access__rioxarray_clipping\nCalculate black-sky, white-sky, and actual albedo (MCD43A) from MCD43A1 BRDF Parameters using R\nXarray Zonal Statistics"
  },
  {
    "objectID": "schedule.html#workshop-schedule",
    "href": "schedule.html#workshop-schedule",
    "title": "Schedule",
    "section": "Workshop Schedule",
    "text": "Workshop Schedule\n\nDay 1 - April 12, 2022\n\n\n\nTime, PST (UTC-7)\nEvent\nLeads/Instructors\n\n\n\n\n2:00 pm\nWelcome / Workshop Expectations\nAaron Friesz (LP DAAC) / Christine Lee (JPL)\n\n\n2:10 pm\nECOSTRESS Build 7 collection Overview\nChristine Lee & Gregory Halverson (JPL)\n\n\n2:25 pm\nEarthdata Cloud Overview\nAaron Friesz (LP DAAC)\n\n\n2:55 pm\nBreak/QA\n\n\n\n3:00 pm\nEarthdata Search Client (GUI)\nAaron Friesz (LP DAAC)\n\n\n3:30 pm\nBreak\n\n\n\n4:00 pm\nGetting set up / Intro to Pangeo\nAaron Friesz (LP DAAC)\n\n\n4:30 pm\nIntro to xarray & hvplot\nAaron Friesz (LP DAAC)\n\n\n5:15 pm\nBreak/QA\n\n\n\n\n\nClosing Day 1\n\nThank you!\nJupyterHub: close out.\n\nclose out your JupyterHub instance if you are finished for the day, following these instructions.\n\nContinued work.\n\nYou’re welcome to continue working beyond the workshop daily scheduled session, using JupyterHub.\n\nAgenda for tomorrow: what’s coming next.\n\n\n\n\nDay 2 - April 13, 2022\n\n\n\nTime, PST (UTC-7)\nEvent\nLeads/Instructors\n\n\n\n\n2:00 pm\nWelcome Back / Earthdata Authentication: Set up netrc file & Generate EDL Tokens\nAaron Friesz (LP DAAC)\n\n\n2:10 pm\nEarthdata Cloud: Search and Discovery - CMR API\nAaron Friesz (LP DAAC)\n\n\n2:45 pm\nBreak/QA\n\n\n\n2:50 pm\nEarthdata Cloud: Search and Discovery - Data Access\nAaron Friesz (LP DAAC)\n\n\n3:30 pm\nBreak\n\n\n\n4:00 pm\nComparing TNC Tree Data to ECOSTRESS Use Case\nGregory Halverson (JPL)\n\n\n5:00 pm\nBreak/QA\n\n\n\n\n\nClosing Day 2\n\nThank you!\nYou will continue to have access to the 2i2c JupyterHub in AWS for two weeks following the ECOSTRESS Cloud Workshop. You may use that time to continue work and all learn more about migrating data accass routines and science workflows to the Cloud. This cloud compute environment is supported by the NASA Openscapes project."
  },
  {
    "objectID": "schedule.html#getting-help-during-the-workshop",
    "href": "schedule.html#getting-help-during-the-workshop",
    "title": "Schedule",
    "section": "Getting help during the Workshop",
    "text": "Getting help during the Workshop\nWe will use the ECOSTRESS Slack Workspace as our main channels for help. Please use Slack to post questions."
  },
  {
    "objectID": "notebooks/Getting_Started/NASA_Earthdata_Authentication.html#summary",
    "href": "notebooks/Getting_Started/NASA_Earthdata_Authentication.html#summary",
    "title": "2022 ECOSTRESS Cloud Workshop",
    "section": "Summary",
    "text": "Summary\nThis notebook creates a hidden .netrc file (_netrc for Window OS) with Earthdata login credentials in your home directory. This file is needed to access NASA Earthdata assets from a scripting environment like Python.\n\nEarthdata Login\nAn Earthdata Login account is required to access data, as well as discover restricted data, from the NASA Earthdata system. Thus, to access NASA data, you need Earthdata Login. Please visit https://urs.earthdata.nasa.gov to register and manage your Earthdata Login account. This account is free to create and only takes a moment to set up.\n\n\nAuthentication via netrc File\nYou will need a netrc file containing your NASA Earthdata Login credentials in order to execute the notebooks. A netrc file can be created manually within text editor and saved to your home directory. An example of the required content is below.\nmachine urs.earthdata.nasa.gov\nlogin <USERNAME>\npassword <PASSWORD>\n<USERNAME> and <PASSWORD> would be replaced by your actual Earthdata Login username and password respectively."
  },
  {
    "objectID": "notebooks/Getting_Started/NASA_Earthdata_Authentication.html#import-required-packages",
    "href": "notebooks/Getting_Started/NASA_Earthdata_Authentication.html#import-required-packages",
    "title": "2022 ECOSTRESS Cloud Workshop",
    "section": "Import Required Packages",
    "text": "Import Required Packages\n\nfrom netrc import netrc\nfrom subprocess import Popen\nfrom platform import system\nfrom getpass import getpass\nimport os\n\nThe code below will:\n\ncheck what operating system (OS) is being used to determine which netrc file to check for/create (.netrc or _netrc)\ncheck if you have an netrc file, and if so, varify if those credentials are for the Earthdata endpoint\ncreate a netrc file if a netrc file is not present.\n\n\nurs = 'urs.earthdata.nasa.gov'    # Earthdata URL endpoint for authentication\nprompts = ['Enter NASA Earthdata Login Username: ',\n           'Enter NASA Earthdata Login Password: ']\n\n# Determine the OS (Windows machines usually use an '_netrc' file)\nnetrc_name = \"_netrc\" if system()==\"Windows\" else \".netrc\"\n\n# Determine if netrc file exists, and if so, if it includes NASA Earthdata Login Credentials\ntry:\n    netrcDir = os.path.expanduser(f\"~/{netrc_name}\")\n    netrc(netrcDir).authenticators(urs)[0]\n\n# Below, create a netrc file and prompt user for NASA Earthdata Login Username and Password\nexcept FileNotFoundError:\n    homeDir = os.path.expanduser(\"~\")\n    Popen('touch {0}{2} | echo machine {1} >> {0}{2}'.format(homeDir + os.sep, urs, netrc_name), shell=True)\n    Popen('echo login {} >> {}{}'.format(getpass(prompt=prompts[0]), homeDir + os.sep, netrc_name), shell=True)\n    Popen('echo \\'password {} \\'>> {}{}'.format(getpass(prompt=prompts[1]), homeDir + os.sep, netrc_name), shell=True)\n    # Set restrictive permissions\n    Popen('chmod 0600 {0}{1}'.format(homeDir + os.sep, netrc_name), shell=True)\n\n    # Determine OS and edit netrc file if it exists but is not set up for NASA Earthdata Login\nexcept TypeError:\n    homeDir = os.path.expanduser(\"~\")\n    Popen('echo machine {1} >> {0}{2}'.format(homeDir + os.sep, urs, netrc_name), shell=True)\n    Popen('echo login {} >> {}{}'.format(getpass(prompt=prompts[0]), homeDir + os.sep, netrc_name), shell=True)\n    Popen('echo \\'password {} \\'>> {}{}'.format(getpass(prompt=prompts[1]), homeDir + os.sep, netrc_name), shell=True)\n\n\nSee if the file was created\nIf the file was created, we’ll see a .netrc file (_netrc for Window OS) in the list printed below. To view the contents from a Jupyter environment, click File on the top toolbar, select Open from Path…, type .netrc, and click Open. The .netrc file will open within the text editor.\n\n!!! Beware, your password will be visible if the .netrc file is opened in the text editor.\n\n\n!ls -al ~/"
  },
  {
    "objectID": "notebooks/Getting_Started/Intro_xarray_hvplot.html#why-do-we-need-xarray",
    "href": "notebooks/Getting_Started/Intro_xarray_hvplot.html#why-do-we-need-xarray",
    "title": "2022 ECOSTRESS Cloud Workshop",
    "section": "Why do we need xarray?",
    "text": "Why do we need xarray?\nAs Geoscientists, we often work with time series of data with two or more dimensions: a time series of calibrated, orthorectified satellite images; two-dimensional grids of surface air temperature from an atmospheric reanalysis; or three-dimensional (level, x, y) cubes of ocean salinity from an ocean model. These data are often provided in GeoTIFF, NetCDF or HDF format with rich and useful metadata that we want to retain, or even use in our analysis. Common analyses include calculating means, standard deviations and anomalies over time or one or more spatial dimensions (e.g. zonal means). Model output often includes multiple variables that you want to apply similar analyses to.\n\n\n\nA schematic of multi-dimensional data\n\n\nThe schematic above shows a typical data structure for multi-dimensional data. There are two data cubes, one for temperature and one for precipitation. Common coordinate variables, in this case latitude, longitude and time are associated with each variable. Each variable, including coordinate variables, will have a set of attributes: name, units, missing value, etc. The file containing the data may also have attributes: source of the data, model name coordinate reference system if the data are projected. Writing code using low-level packages such as netcdf4 and numpy to read the data, then perform analysis, and write the results to file is time consuming and prone to errors."
  },
  {
    "objectID": "notebooks/Getting_Started/Intro_xarray_hvplot.html#what-is-xarray",
    "href": "notebooks/Getting_Started/Intro_xarray_hvplot.html#what-is-xarray",
    "title": "2022 ECOSTRESS Cloud Workshop",
    "section": "What is xarray",
    "text": "What is xarray\nxarray is an open-source project and python package to work with labelled multi-dimensional arrays. It is leverages numpy, pandas, matplotlib and dask to build Dataset and DataArray objects with built-in methods to subset, analyze, interpolate, and plot multi-dimensional data. It makes working with multi-dimensional data cubes efficient and fun. It will change your life for the better. You’ll be more attractive, more interesting, and better equiped to take on lifes challenges."
  },
  {
    "objectID": "notebooks/Getting_Started/Intro_xarray_hvplot.html#what-you-will-learn-from-this-tutorial",
    "href": "notebooks/Getting_Started/Intro_xarray_hvplot.html#what-you-will-learn-from-this-tutorial",
    "title": "2022 ECOSTRESS Cloud Workshop",
    "section": "What you will learn from this tutorial",
    "text": "What you will learn from this tutorial\nIn this tutorial you will learn how to:\n\nload a netcdf file into xarray\ninterrogate the Dataset and understand the difference between DataArray and Dataset\nsubset a Dataset\ncalculate annual and monthly mean fields\ncalculate a time series of zonal means\nplot these results\n\nAs always, we’ll start by importing xarray. We’ll follow convention by giving the module the shortname xr\n\nimport xarray as xr\nxr.set_options(keep_attrs=True)\nimport hvplot.xarray\n\nI’m going to use one of xarray’s tutorial datasets. In this case, air temperature from the NCEP reanalysis. I’ll assign the result of the open_dataset to ds. I may change this to access a dataset directly\n\nds = xr.tutorial.open_dataset(\"air_temperature\")\n\nAs we are in an interactive environment, we can just type ds to see what we have.\n\nds\n\nFirst thing to notice is that ds is an xarray.Dataset object. It has dimensions, lat, lon, and time. It also has coordinate variables with the same names as these dimensions. These coordinate variables are 1-dimensional. This is a NetCDF convention. The Dataset contains one data variable, air. This has dimensions (time, lat, lon).\nClicking on the document icon reveals attributes for each variable. Clicking on the disk icon reveals a representation of the data.\nEach of the data and coordinate variables can be accessed and examined using the variable name as a key.\n\nds.air\n\n\nds['air']\n\nThese are xarray.DataArray objects. This is the basic building block for xarray.\nVariables can also be accessed as attributes of ds.\n\nds.time\n\nA major difference between accessing a variable as an attribute versus using a key is that the attribute is read-only but the key method can be used to update the variable. For example, if I want to convert the units of air from Kelvin to degrees Celsius.\n\nds['air'] = ds.air - 273.15\n\nThis approach can also be used to add new variables\n\nds['air_kelvin'] = ds.air + 273.15\n\n\nds\n\nIt is helpful to update attributes such as units, this saves time, confusion and mistakes, especially when you save the dataset.\n\nds['air'].attrs['units'] = 'degC'\n\n\nds"
  },
  {
    "objectID": "notebooks/Getting_Started/Intro_xarray_hvplot.html#subsetting-and-indexing",
    "href": "notebooks/Getting_Started/Intro_xarray_hvplot.html#subsetting-and-indexing",
    "title": "2022 ECOSTRESS Cloud Workshop",
    "section": "Subsetting and Indexing",
    "text": "Subsetting and Indexing\nSubsetting and indexing methods depend on whether you are working with a Dataset or DataArray. A DataArray can be accessed using positional indexing just like a numpy array. To access the temperature field for the first time step, you do the following.\n\nds['air'][0,:,:]\n\nNote this returns a DataArray with coordinates but not attributes.\nHowever, the real power is being able to access variables using coordinate variables. I can get the same subset using the following. (It’s also more explicit about what is being selected and robust in case I modify the DataArray and expect the same output.)\n\nds['air'].sel(time='2013-01-01').time\n\n\nds.air.sel(time='2013-01-01')\n\nI can also do slices. I’ll extract temperatures for the state of Colorado. The bounding box for the state is [-109 E, -102 E, 37 N, 41 N].\nIn the code below, pay attention to both the order of the coordinates and the range of values. The first value of the lat coordinate variable is 41 N, the second value is 37 N. Unfortunately, xarray expects slices of coordinates to be in the same order as the coordinates. Note lon is 0 to 360 not -180 to 180, and I let python calculate it for me within the slice.\n\nds.air.sel(lat=slice(41.,37.), lon=slice(360-109,360-102))\n\nWhat if we want temperature for a point, for example Denver, CO (39.72510678889283 N, -104.98785545855408 E). xarray can handle this! If we just want data from the nearest grid point, we can use sel and specify the method as “nearest”.\n\ndenver_lat, denver_lon = 39.72510678889283, -104.98785545855408\n\n\nds.air.sel(lat=denver_lat, lon=360+denver_lon, method='nearest').hvplot()\n\nIf we want to interpolate, we can use interp(). In this case I use linear or bilinear interpolation.\ninterp() can also be used to resample data to a new grid and even reproject data\n\nds.air.interp(lat=denver_lat, lon=360+denver_lon, method='linear')\n\nsel() and interp() can also be used on Dataset objects.\n\nds.sel(lat=slice(41,37), lon=slice(360-109,360-102))\n\n\nds.interp(lat=denver_lat, lon=360+denver_lon, method='linear')"
  },
  {
    "objectID": "notebooks/Getting_Started/Intro_xarray_hvplot.html#analysis",
    "href": "notebooks/Getting_Started/Intro_xarray_hvplot.html#analysis",
    "title": "2022 ECOSTRESS Cloud Workshop",
    "section": "Analysis",
    "text": "Analysis\nAs a simple example, let’s try to calculate a mean field for the whole time range.\n\nds.mean(dim='time').hvplot()\n\nWe can also calculate a zonal mean (averaging over longitude)\n\nds.mean(dim='lon').hvplot()\n\nOther aggregation methods include min(), max(), std(), along with others.\n\nds.std(dim='time').hvplot()\n\nThe data we have are in 6h timesteps. This can be resampled to daily or monthly. If you are familiar with pandas, xarray uses the same methods.\n\nds_mon = ds.resample(time='M').mean()\nds_mon\n\nThis is a really short time series but as an example, let’s calculate a monthly climatology (at least for 2 months). For this we can use groupby()\n\nds_clim = ds_mon.groupby(ds_mon.time.dt.month).mean()\nds_clim"
  },
  {
    "objectID": "notebooks/Getting_Started/Intro_xarray_hvplot.html#plot-results",
    "href": "notebooks/Getting_Started/Intro_xarray_hvplot.html#plot-results",
    "title": "2022 ECOSTRESS Cloud Workshop",
    "section": "Plot results",
    "text": "Plot results\nFinally, let’s plot the results! This will plot the lat/lon axes of the original ds DataArray.\n\nds_clim.air.sel(month=10).hvplot()"
  }
]